# Assignment 2: OpenMP, CUDA и гетерогенные вычисления

**Задача 1. Введение в гетерогенную параллелизацию**

Гетерогенная параллелизация - это использование разных типов вычислительных устройств (CPU и GPU) в рамках одного приложения для ускорения вычислений.

Основные аспекты:

- Различия между CPU и GPU: CPU обладает меньшим числом мощных ядер и оптимизирован для последовательных и ветвистых задач; GPU имеет сотни/тысячи простых потоковых ядер, подходящих для массово-параллельных операций.

- Преимущества гетерогенной параллелизации: Позволяет распределять задачи по наиболее подходящему устройству, повышая общую производительность и снижая время вычислений.

- Примеры реальных приложений: рендеринг графики, машинное обучение (обучение нейронных сетей), научные вычисления (моделирование молекул, климатические модели), финансовое моделирование.

**Задача 2. Работа с массивами и OpenMP**

**Реализация:**
1. Создан массив из 10 000 случайных чисел.
2. Найдены минимальные и максимальные значения:

   2.1 Последовательно (CPU).
   
   2.2 Параллельно с использованием OpenMP.

**Результаты:**

```bash
Sequential: min = 19, max = 32759, time = 0.0706 ms
Parallel: min = 19, max = 32759, time = 1.614 ms
```
**Вывод:**
Хотя параллельная версия использует несколько потоков, на маленьком массиве она может работать медленнее из-за накладных расходов на создание потоков. На больших данных эффект параллелизма становится заметнее.

**Задача 3. Параллельная сортировка с OpenMP**

**Реализация:**

1. Сортировка выбором (selection sort) реализована последовательно и с использованием OpenMP.
2. Тестировались массивы размером 1 000 и 10 000 элементов.

**Результаты:**
```bash
Размер массива: 1000
Sequential sort time: 3.3505 ms
Parallel sort time  : 39.9668 ms

Размер массива: 10000
Sequential sort time: 392.643 ms
Parallel sort time  : 274.612 ms
```

**Вывод:**
На маленьких массивах накладные расходы на параллельные вычисления делают GPU/OpenMP версии медленнее. На больших массивах параллельная версия показывает заметное ускорение.

**Задача 4. Сортировка на GPU с использованием CUDA**
**Реализация:**

1. Используется параллельная сортировка слиянием (merge sort) на GPU.

2. Массив разделяется на блоки, каждый блок сортируется независимо, затем блоки сливаются параллельно.

3. Производительность замерялась для массивов 10 000 и 100 000 элементов.

**Результаты:**
```bash
Detected 1 CUDA device(s)

Размер массива: 10000
GPU MergeSort time: 5.30532 ms

Размер массива: 100000
GPU MergeSort time: 44.7019 ms
```

**Вывод:** 
GPU эффективно обрабатывает большие массивы, особенно при массово-параллельной сортировке блоков. Для небольших массивов ускорение может быть незначительным.

# Контрольные вопросы

**1. Что понимается под гетерогенной параллелизацией?**

Использование CPU и GPU совместно для распределения задач по наиболее подходящему устройству для ускорения вычислений.

**2. В чём принципиальные различия архитектур CPU и GPU?**

CPU - меньше ядер, мощные и оптимизированы для последовательных задач. GPU - много простых ядер, оптимизировано для параллельных задач.

**3. Какие типы задач лучше подходят для GPU, а какие — для CPU?**

GPU: массово-параллельные вычисления (матрицы, обработка изображений).
CPU: ветвистые, условные, последовательные задачи.

**4. Почему не все алгоритмы эффективно распараллеливаются с OpenMP?**

Из-за зависимостей между итерациями или высокого накладного времени на создание потоков.

**5. В чём заключается основная идея алгоритма сортировки слиянием?**

Разделяй и властвуй: массив делится на части, сортируются и затем сливаются в один отсортированный массив.

**6. Какие сложности возникают при реализации сортировки слиянием на GPU?**

Сложность управления памятью, синхронизации потоков и оптимального распределения блоков.

**7. Как выбор размера блока и сетки влияет на производительность на GPU?**

Неправильный размер блоков может привести к недостаточному использованию потоков или перегрузке shared memory, снижая производительность.

**8. Почему гетерогенный подход может быть эффективнее использования только CPU или GPU?**

Позволяет оптимально распределять задачи по устройствам, используя сильные стороны каждого и достигая максимальной производительности.



